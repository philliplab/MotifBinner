```{r Setup}
library(MotifBinner)
```

# Investigation of various approach to treating mislabel detection

## Overview

Given a bin of sequences that are theoretically from only a single virus
molecule, remove all of those that are actually from a different molecule.

This is accomplished by looking at the distances between each of the sequences
and removing the outliers.

The difficult parts are deciding how to compute the distances efficiently and
setting the thresholds that start and stop the process.

This process is further complicated by these concerns:
1) bin sizes varies from 1 to several hundred
2) We have to deal with indels
3) This process must be completely automated
4) This process must be very computationally efficient

## Testing strategy

We need to test the system using bins with known answers. 

### Test Data

As always, the design data structure for the test data is important. Use a
structure like this:

```{r eval=FALSE, echo=TRUE}
list('test1' = list('in' = DNAStringSet(...),
                    'out' = DNAStringSet(...)),
     'test2' = ...)
```

The data is available in the package:
```{r echo=TRUE}
test_dat <- get_mislabel_test_data()
```

Using this data for a 'bin' by putting the 'src' and 'out' data together and check
that only the 'out' data is removed and all the 'src' data is kept.

### Basic Code for running tests

Basic code to run the tests is available from the package:

```{r, eval=FALSE, echo=TRUE}
score_classification()
```

### Metrics of interest

A number of metrics must be considered when looking at the accuracy of
classification.

Keep it basic. 

Consider these standard classification metrics:

#### Sensitivity:
Number of true 'in' classifications / (Total size of true 'in' population)

#### Specificity:
Number of true 'out' classifications / (Total size of the 'out' population)

Maximize both simultaneously

Now, in addition to these two, there are other metrics of interest that we can
derive based on our knowledge of the system.

#### Maximum distance in the final dataset: 
We know that the only source of errors
should be the sequencing process. We have access to data about the error rates
of the sequencing process. We can use this to make a statement like:

The sequencing process is accurate to such a degree that no two reads of the
same molecule should differ by more than one base per 100 bases. Build a metric
around this information.

#### Speed

The time it took to classify the reads in the bin.

## The different strategies

Design and implement a who set of strategies and then benchmark them to find
the best ones.

### Remove None

This strategy keeps all the data

Use the random strategy but set the parameter 'n' to 0. So that 0 percent of
the data will be randomly removed.

```{r}
kable(score_all_classifications(test_dat, 'random', params = list(n=0)))
```

### Remove Random

This strategy removes 40% of the sample at random

```{r}
kable(score_all_classifications(test_dat, 'random', params = list(n=0.4)))
```
### Information Variance Balance

This strategy will keep on removing the most outlying sequence as long as is
leads to a percentage reduction in variance that is x times larger than the
percentage of information that was discarded

```{r}
kable(score_all_classifications(test_dat, 'infovar_balance', params = list()))
```

### The silver bullet

To be devised

